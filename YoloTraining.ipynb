{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File to Train YOLO\n",
    "\n",
    "This is an example file on how to run some yolo training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.utils import verify_image_label\n",
    "from ultralytics import YOLO\n",
    "import yaml  \n",
    "from Dataset import LargeRocksDataset\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yaml_file(output_path, path_params, class_names={0: \"Rock\"}, augmentation_params=None):\n",
    "\n",
    "    # Extract paths from the dictionary\n",
    "    dataset_path = path_params.get(\"dataset_path\", \"\")\n",
    "    train_path = path_params.get(\"train_path\", \"\")\n",
    "    val_path = path_params.get(\"val_path\", \"\")\n",
    "    test_path = path_params.get(\"test_path\", \"\")\n",
    "\n",
    "    # Build the data dictionary for YAML\n",
    "    data = {\n",
    "        \"path\": dataset_path,\n",
    "        \"train\": train_path,\n",
    "        \"val\": val_path,\n",
    "        \"test\": test_path,\n",
    "        \"names\": class_names\n",
    "    }\n",
    "\n",
    "    nc = len(class_names)\n",
    "    data[\"nc\"] = nc\n",
    "\n",
    "    if augmentation_params:\n",
    "        data[\"augmentation\"] = augmentation_params\n",
    "\n",
    "    # Write the YAML file\n",
    "    with open(output_path, 'w') as yaml_file:\n",
    "        yaml.dump(data, yaml_file, default_flow_style=False)\n",
    "    \n",
    "    print(f\"YAML file written to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"swissImage_50cm_patches\"\n",
    "label_file = \"large_rock_dataset.json\"\n",
    "output_path = \"YOLO\"\n",
    "split = [80,10,10]\n",
    "combined_rgb_hillshade = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocks_dataset = LargeRocksDataset(image_folder, label_file, output_path, split, combined_rgb_hillshade)\n",
    "rocks_dataset.process_dataset()\n",
    "rocks_dataset.remove_duplicates_in_labels()\n",
    "rocks_dataset.check_images_and_label_size()\n",
    "rocks_dataset.print_actual_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO seems to only work when the entire paths are given, please hence specify them here when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/YOLO\"\n",
    "train_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/YOLO/images/train\"\n",
    "val_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/YOLO/images/val\"\n",
    "test_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/YOLO/images/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml = \"data.yaml\"\n",
    "\n",
    "# Define the paths in a dictionary\n",
    "path_params = {\n",
    "                \"dataset_path\": dataset_path, \n",
    "                \"train_path\": train_path, \n",
    "                \"val_path\": val_path, \n",
    "                \"test_path\": test_path, \n",
    "            }\n",
    "\n",
    "# Define class names and augmentation parameters\n",
    "class_names = {\n",
    "                0: \"Rock\"\n",
    "            }\n",
    "\n",
    "\n",
    "# Call the function\n",
    "write_yaml_file(output_yaml, path_params, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEVICE = \"mps\" # Set the device to 'cpu', 'mps' or 'cuda'\n",
    "EPOCHS = 2  # Number of epochs to train\n",
    "OPTIMIZER = \"AdamW\"  # Optimizer to use for training\n",
    "BATCH_SIZE = 8  # Batch size for training\n",
    "IMG_SIZE = 640  # Image size for training\n",
    "SAVE_DIR = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/runs/train\"\n",
    "PRETRAINED = True\n",
    "DROPOUT = 0\n",
    "MOSAIC = 0 # Use Mosaic augmentation --> dont make sense for rock detection\n",
    "SCALE = 0 # Use Scale augmentation --> dont make sense for rock detection\n",
    "augmentation_params = {\n",
    "                        \"hsv_h\": 0.0,\n",
    "                        \"hsv_s\": 0.0,\n",
    "                        \"hsv_v\": 0.0,\n",
    "                        \"flipud\": 0.0,\n",
    "                        \"fliplr\": 0.0, \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML configuration\n",
    "model = YOLO('yolov8n.pt')  # Load YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=\"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/data.yaml\",\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    multi_scale=False, overlap_mask=False, mask_ratio=0, dropout=0, iou=0.7, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0, hsv_v=0.4, degrees=0, translate=0.1, scale=0, shear=0, perspective=0.0, flipud=0, fliplr=0.5, bgr=0.0, mosaic=0, mixup=0.0, copy_paste=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=\"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/data.yaml\",\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    #device=DEVICE,\n",
    "    optimizer=OPTIMIZER,\n",
    "    pretrained=PRETRAINED,\n",
    "    dropout=DROPOUT,\n",
    "    mosaic=MOSAIC,\n",
    "    scale=SCALE,\n",
    "    translate= 0.0,\n",
    "    hsv_h=augmentation_params[\"hsv_h\"],\n",
    "    hsv_s=augmentation_params[\"hsv_s\"],\n",
    "    hsv_v=augmentation_params[\"hsv_v\"],\n",
    "    flipud=augmentation_params[\"flipud\"],\n",
    "    fliplr=augmentation_params[\"fliplr\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
