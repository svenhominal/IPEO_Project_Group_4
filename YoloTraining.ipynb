{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 640 images\n",
      "Percentage: 64.52%\n",
      "Test: 352 images\n",
      "Percentage: 35.48%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "label_file = \"large_rock_dataset.json\"\n",
    "\n",
    "with open(label_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "splits = [tile.get('split', 'train') for tile in data['dataset']]  # Default to 'train' if missing\n",
    "split_counts = Counter(splits)\n",
    "\n",
    "for split, count in split_counts.items():\n",
    "    print(f\"{split.capitalize()}: {count} images\")\n",
    "    print(f\"Percentage: {count / len(splits) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "\n",
    "\n",
    "class LargeRocksDatasetV2:\n",
    "    def __init__(self, image_folder: str, json_dataset: str, output_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the dataset processor\n",
    "        \n",
    "        Args:\n",
    "            image_folder (str): Path to folder containing `.tif` images\n",
    "            json_dataset (str): Path to JSON dataset file\n",
    "            output_path (str): Path to save YOLOv8 formatted dataset\n",
    "        \"\"\"\n",
    "        self.image_folder = image_folder\n",
    "        self.label_file = json_dataset\n",
    "        self.output_path = output_path\n",
    "        \n",
    "        # Define directories for train and test splits\n",
    "        self.splits = [\"train\", \"test\"]\n",
    "        self.image_dir = output_path\n",
    "        self.label_dir = output_path\n",
    "        \n",
    "        # Create directories for each split\n",
    "        for split in self.splits:\n",
    "            os.makedirs(os.path.join(self.image_dir, split, \"images\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.label_dir, split, \"labels\"), exist_ok=True)\n",
    "    \n",
    "    def _convert_bbox(self, rel_loc: Tuple[float, float], bbox_size: Tuple[int, int], img_size: Tuple[int, int]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Convert bounding box info to YOLO format: [class_id, x_center, y_center, width, height].\n",
    "        \n",
    "        Args:\n",
    "            rel_loc (Tuple[float, float]): Relative location of the object in the image (normalized).\n",
    "            bbox_size (Tuple[int, int]): Size of the bounding box in pixels.\n",
    "            img_size (Tuple[int, int]): Image size (width, height).\n",
    "        \n",
    "        Returns:\n",
    "            List[float]: Bounding box in YOLO format.\n",
    "        \"\"\"\n",
    "        x_center, y_center = rel_loc\n",
    "        width = bbox_size[0] / img_size[0]\n",
    "        height = bbox_size[1] / img_size[1]\n",
    "        return [0, x_center, y_center, width, height]  # class_id = 0 for rocks\n",
    "    \n",
    "    def process_dataset(self):\n",
    "        \"\"\"\n",
    "        Process the dataset and convert it to YOLOv8 format with train/test splits.\n",
    "        \"\"\"\n",
    "        # Load the annotations JSON\n",
    "        with open(self.label_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Iterate over each image in the dataset\n",
    "        for tile in data['dataset']:\n",
    "            file_name = tile['file_name']\n",
    "            img_path = os.path.join(self.image_folder, file_name)\n",
    "            \n",
    "            # Check if the image exists\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Image {img_path} not found. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            img_width, img_height = tile['width'], tile['height']\n",
    "            annotations = tile.get('rocks_annotations', [])\n",
    "            split = tile.get('split', \"train\")  # Default to 'train' if no split is specified\n",
    "            \n",
    "            # Ensure split is either train or test\n",
    "            if split not in self.splits:\n",
    "                print(f\"Skipping split '{split}' for file {file_name}.\")\n",
    "                continue\n",
    "            \n",
    "            # Copy the image to the appropriate YOLO image folder\n",
    "            dst_img_path = os.path.join(self.image_dir, split, \"images\", file_name)\n",
    "            shutil.copy(img_path, dst_img_path)\n",
    "            \n",
    "            # Prepare labels for this image\n",
    "            label_lines = []\n",
    "            for annotation in annotations:\n",
    "                rel_loc = annotation['relative_within_patch_location']\n",
    "                bbox_size = annotation.get('bbox_size', [30, 30])  # Default bbox size to 30x30\n",
    "                yolo_bbox = self._convert_bbox(rel_loc, bbox_size, (img_width, img_height))\n",
    "                label_lines.append(\" \".join(map(str, yolo_bbox)))\n",
    "            \n",
    "            # Save labels to the appropriate folder\n",
    "            label_file = os.path.join(self.label_dir, split, \"labels\", f\"{os.path.splitext(file_name)[0]}.txt\")\n",
    "            with open(label_file, 'w') as lf:\n",
    "                lf.write(\"\\n\".join(label_lines))\n",
    "        \n",
    "        print(f\"Dataset ({self.image_folder}) converted to YOLO format with train/test splits at {self.output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (swissImage_50cm_patches) converted to YOLO format with train/test splits at dataset_rgb_only\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_folder = \"swissImage_50cm_patches\"  # Path to image folder\n",
    "label_file = \"large_rock_dataset.json\"  # Path to JSON annotation file\n",
    "output_path = \"dataset_rgb_only\"  # Path to save processed dataset\n",
    "\n",
    "rocks_dataset = LargeRocksDatasetV2(image_folder, label_file, output_path)\n",
    "rocks_dataset.process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (8.3.40)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (2.5.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Results:\n",
      "Image File: dataset_rgb_only/train/images/2581_1126_0_2.tif\n",
      "Labels: [[          0        0.12        0.39    0.046875    0.046875]]\n",
      "Image Shape: (640, 640)\n",
      "Segments: []\n",
      "Keypoints: None\n",
      "Missing Labels: 0\n",
      "Found Labels: 1\n",
      "Empty Labels: 0\n",
      "Corrupt Files: 0\n",
      "Message: \n"
     ]
    }
   ],
   "source": [
    "from ultralytics.data.utils import verify_image_label\n",
    "import os\n",
    "\n",
    "# Define the required arguments\n",
    "image_file = \"dataset_rgb_only/train/images/2581_1126_0_2.tif\"  # Path to the image file\n",
    "label_file = \"dataset_rgb_only/train/labels/2581_1126_0_2.txt\"  # Path to the corresponding label file\n",
    "prefix = \"[VERIFY] \"  # Optional log message prefix\n",
    "keypoint = False  # Whether the labels include keypoints\n",
    "num_classes = 1  # Total number of classes in the dataset\n",
    "nkpt = 0  # Number of keypoints (if keypoint is True)\n",
    "ndim = 0  # Number of dimensions for keypoints\n",
    "\n",
    "# Verify the image and its label\n",
    "args = (image_file, label_file, prefix, keypoint, num_classes, nkpt, ndim)\n",
    "result = verify_image_label(args)\n",
    "\n",
    "# Output the result\n",
    "print(\"Verification Results:\")\n",
    "print(f\"Image File: {result[0]}\")\n",
    "print(f\"Labels: {result[1]}\")\n",
    "print(f\"Image Shape: {result[2]}\")\n",
    "print(f\"Segments: {result[3]}\")\n",
    "print(f\"Keypoints: {result[4]}\")\n",
    "print(f\"Missing Labels: {result[5]}\")\n",
    "print(f\"Found Labels: {result[6]}\")\n",
    "print(f\"Empty Labels: {result[7]}\")\n",
    "print(f\"Corrupt Files: {result[8]}\")\n",
    "print(f\"Message: {result[9]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed in file: dataset_rgb_only/train/labels/2588_1133_0_2.txt\n",
      "Duplicates removed in file: dataset_rgb_only/train/labels/2704_1127_3_3.txt\n",
      "Duplicates removed in file: dataset_rgb_only/train/labels/2588_1133_1_2.txt\n",
      "Duplicates removed in file: dataset_rgb_only/train/labels/2582_1127_0_1.txt\n",
      "Duplicates removed in file: dataset_rgb_only/train/labels/2598_1132_1_3.txt\n",
      "Duplicates removed in file: dataset_rgb_only/train/labels/2598_1132_0_3.txt\n",
      "Duplicates removed in file: dataset_rgb_only/test/labels/2626_1102_2_0.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def remove_duplicates_in_labels(base_dir):\n",
    "    \"\"\"\n",
    "    Traverse the labels directory and remove duplicate lines in each label file.\n",
    "    Print a message only if duplicates were removed.\n",
    "    \"\"\"\n",
    "    subfolders = ['train/labels', 'test/labels']\n",
    "    \n",
    "    for subfolder in subfolders:\n",
    "        labels_path = os.path.join(base_dir, subfolder)\n",
    "        \n",
    "        if not os.path.exists(labels_path):\n",
    "            print(f\"Directory not found: {labels_path}\")\n",
    "            continue\n",
    "        \n",
    "        for label_file in os.listdir(labels_path):\n",
    "            file_path = os.path.join(labels_path, label_file)\n",
    "            \n",
    "            if not label_file.endswith('.txt'):\n",
    "                continue  # Skip non-label files\n",
    "            \n",
    "            try:\n",
    "                # Read file and remove duplicates\n",
    "                with open(file_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                unique_lines = list(set(lines))  # Remove duplicates\n",
    "                \n",
    "                # Check if duplicates were removed\n",
    "                if len(lines) != len(unique_lines):\n",
    "                    # Write back the unique lines\n",
    "                    with open(file_path, 'w') as f:\n",
    "                        f.writelines(sorted(unique_lines))  # Sorting for consistency\n",
    "                    \n",
    "                    print(f\"Duplicates removed in file: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Specify the base directory of your dataset\n",
    "base_dataset_dir = 'dataset_rgb_only'\n",
    "\n",
    "# Call the function\n",
    "remove_duplicates_in_labels(base_dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def write_yaml_file(output_path, dataset_path, train_path, val_path, test_path, class_names):\n",
    "    \"\"\"\n",
    "    Write a YAML file for the dataset configuration.\n",
    "    \n",
    "    Args:\n",
    "        output_path (str): Path to save the YAML file.\n",
    "        dataset_path (str): Base path to the dataset.\n",
    "        train_path (str): Path to the training data folder.\n",
    "        val_path (str): Path to the validation data folder.\n",
    "        test_path (str): Path to the test data folder.\n",
    "        class_names (dict): Dictionary with class names (e.g., {0: 'Rock'}).\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"path\": dataset_path,\n",
    "        \"train\": train_path,\n",
    "        \"val\": val_path,\n",
    "        \"test\": test_path,\n",
    "        \"names\": class_names\n",
    "    }\n",
    "    \n",
    "    # Write the YAML file\n",
    "    with open(output_path, 'w') as yaml_file:\n",
    "        yaml.dump(data, yaml_file, default_flow_style=False)\n",
    "    \n",
    "    print(f\"YAML file written to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file written to: data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "output_yaml = \"data.yaml\"\n",
    "\n",
    "## You should add your own entire paths here, there seem to have been some issues in the past\n",
    "\n",
    "dataset_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only\" \n",
    "train_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only/train\"\n",
    "val_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only/train\"\n",
    "test_path = \"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only/test\"\n",
    "\n",
    "\n",
    "class_names = {0: \"Rock\"}\n",
    "\n",
    "write_yaml_file(output_yaml, dataset_path, train_path, val_path, test_path, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:02<00:00, 2.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YAML configuration\n",
    "model = YOLO('yolov8n.pt')  # Load YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.43 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.40 🚀 Python-3.11.5 torch-2.5.0 MPS (Apple M2 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/janclevorn/runs/detect/train18\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only/train/labels... 640 images, 320 backgrounds, 0 corrupt: 100%|██████████| 640/640 [00:00<00:00, 2044.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only/train/labels.cache\n",
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 154, len(boxes) = 3152. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/dataset_rgb_only/train/labels.cache... 640 images, 320 backgrounds, 0 corrupt: 100%|██████████| 640/640 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 154, len(boxes) = 3152. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/janclevorn/runs/detect/train18/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/janclevorn/runs/detect/train18\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1       4.9G      2.763      3.655      1.569         75        640: 100%|██████████| 40/40 [01:04<00:00,  1.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   5%|▌         | 1/20 [00:14<04:26, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  10%|█         | 2/20 [00:22<03:12, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  15%|█▌        | 3/20 [00:31<02:51, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|██        | 4/20 [00:39<02:28,  9.26s/it]/Users/janclevorn/miniconda3/envs/IPEO/lib/python3.11/site-packages/ultralytics/utils/tal.py:143: UserWarning: MPS: nonzero op is not natively supported for the provided input on MacOS14Falling back on CPU. This may have performance implications.See github.com/pytorch/pytorch/issues/122916 for further info (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:309.)\n",
      "  bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 5/20 [00:49<02:22,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  30%|███       | 6/20 [00:56<02:00,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  35%|███▌      | 7/20 [01:07<02:01,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|████      | 8/20 [01:16<01:50,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  45%|████▌     | 9/20 [01:23<01:34,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 10/20 [01:32<01:28,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  55%|█████▌    | 11/20 [01:41<01:18,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|██████    | 12/20 [01:50<01:09,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  65%|██████▌   | 13/20 [02:00<01:04,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  70%|███████   | 14/20 [02:07<00:50,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|███████▌  | 15/20 [02:16<00:43,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|████████  | 16/20 [02:23<00:32,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  85%|████████▌ | 17/20 [02:31<00:24,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  90%|█████████ | 18/20 [02:40<00:16,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  95%|█████████▌| 19/20 [02:52<00:09,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [03:04<00:00,  9.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        640       3152    0.00925      0.144     0.0326     0.0129\n",
      "\n",
      "1 epochs completed in 0.070 hours.\n",
      "Optimizer stripped from /Users/janclevorn/runs/detect/train18/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/janclevorn/runs/detect/train18/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/janclevorn/runs/detect/train18/weights/best.pt...\n",
      "Ultralytics 8.3.40 🚀 Python-3.11.5 torch-2.5.0 MPS (Apple M2 Pro)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   5%|▌         | 1/20 [00:06<02:03,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  10%|█         | 2/20 [00:11<01:36,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  15%|█▌        | 3/20 [00:16<01:28,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|██        | 4/20 [00:20<01:20,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 5/20 [00:25<01:15,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  30%|███       | 6/20 [00:30<01:07,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  35%|███▌      | 7/20 [00:35<01:04,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|████      | 8/20 [00:40<00:58,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  45%|████▌     | 9/20 [00:44<00:52,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 10/20 [00:49<00:47,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  55%|█████▌    | 11/20 [00:54<00:43,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|██████    | 12/20 [00:59<00:38,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  65%|██████▌   | 13/20 [01:04<00:33,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  70%|███████   | 14/20 [01:09<00:29,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|███████▌  | 15/20 [01:14<00:24,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|████████  | 16/20 [01:19<00:19,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  85%|████████▌ | 17/20 [01:23<00:14,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  90%|█████████ | 18/20 [01:28<00:09,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  95%|█████████▌| 19/20 [01:33<00:04,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [01:38<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        640       3152    0.00891      0.103      0.026     0.0111\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms loss, 130.3ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/janclevorn/runs/detect/train18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 1. Add your own paths\n",
    "## 2. change deive, mps is specifically for MacBook with M1 chip\n",
    "\n",
    "results = model.train(data=\"/Users/janclevorn/Desktop/EPFL/IPEO_Project_Group_4/data.yaml\", epochs=1, imgsz=640, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
